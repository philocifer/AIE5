{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e-IqJAMkwnCF"
      },
      "source": [
        "# Advanced Retrieval with LangChain\n",
        "\n",
        "In the following notebook, we'll explore various methods of advanced retrieval using LangChain!\n",
        "\n",
        "We'll touch on:\n",
        "\n",
        "- Naive Retrieval\n",
        "- Best-Matching 25 (BM25)\n",
        "- Multi-Query Retrieval\n",
        "- Parent-Document Retrieval\n",
        "- Contextual Compression (a.k.a. Rerank)\n",
        "- Ensemble Retrieval\n",
        "- Semantic chunking\n",
        "\n",
        "We'll also discuss how these methods impact performance on our set of documents with a simple RAG chain.\n",
        "\n",
        "There will be two breakout rooms:\n",
        "\n",
        "- 🤝 Breakout Room Part #1\n",
        "  - Task 1: Getting Dependencies!\n",
        "  - Task 2: Data Collection and Preparation\n",
        "  - Task 3: Setting Up QDrant!\n",
        "  - Task 4-10: Retrieval Strategies\n",
        "- 🤝 Breakout Room Part #2\n",
        "  - Activity: Evaluate with Ragas"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4rKP3hgHivpe"
      },
      "source": [
        "# 🤝 Breakout Room Part #1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3xes8oT-xHN7"
      },
      "source": [
        "## Task 1: Getting Dependencies!\n",
        "\n",
        "We're going to need a few specific LangChain community packages, like OpenAI (for our [LLM](https://platform.openai.com/docs/models) and [Embedding Model](https://platform.openai.com/docs/guides/embeddings)) and Cohere (for our [Reranker](https://cohere.com/rerank)).\n",
        "\n",
        "> You do not need to run the following cells if you are running this notebook locally. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MkgFAXWVW3wm",
        "outputId": "636db35c-f05a-4038-ec7a-02360bef2dae"
      },
      "outputs": [],
      "source": [
        "#!pip install -qU langchain langchain-openai langchain-cohere rank_bm25"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dKqYM4Eoxcov"
      },
      "source": [
        "We're also going to be leveraging [Qdrant's](https://qdrant.tech/documentation/frameworks/langchain/) (pronounced \"Quadrant\") VectorDB in \"memory\" mode (so we can leverage it locally in our colab environment)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "s6xav5CxYnML"
      },
      "outputs": [],
      "source": [
        "#!pip install -qU qdrant-client"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z7OHJXzfyJyA"
      },
      "source": [
        "We'll also provide our OpenAI key, as well as our Cohere API key."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7LttlDQUYgSI",
        "outputId": "9dca95ab-4d02-4adf-ec3f-cb831326dc54"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import getpass\n",
        "\n",
        "def set_api_key(key_name: str) -> None:\n",
        "    \"\"\"\n",
        "    Securely set an environment variable if it doesn't already exist.\n",
        "    Prompts the user for input using a password-style hidden input.\n",
        "\n",
        "    Args:\n",
        "        key_name (str): Name of the environment variable to set (e.g., \"OPENAI_API_KEY\")\n",
        "    \"\"\"\n",
        "    if not os.environ.get(key_name):\n",
        "        os.environ[key_name] = getpass.getpass(f\"{key_name}: \")\n",
        "\n",
        "set_api_key(\"OPENAI_API_KEY\")\n",
        "set_api_key(\"COHERE_API_KEY\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### LangSmith Configuration"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [],
      "source": [
        "from uuid import uuid4\n",
        "\n",
        "os.environ[\"LANGCHAIN_PROJECT\"] = f\"AIM - 13 Advanced Retrieval - {uuid4().hex[0:8]}\"\n",
        "os.environ[\"LANGCHAIN_TRACING_V2\"] = \"true\"\n",
        "set_api_key(\"LANGCHAIN_API_KEY\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mw304iAFyRtl"
      },
      "source": [
        "## Task 2: Data Collection and Preparation\n",
        "\n",
        "We'll be using some reviews from the 4 movies in the John Wick franchise today to explore the different retrieval strategies.\n",
        "\n",
        "These were obtained from IMDB, and are available in the [AIM Data Repository](https://github.com/AI-Maker-Space/DataRepository)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xXKHcZmKzDwT"
      },
      "source": [
        "### Data Collection\n",
        "\n",
        "We can simply `wget` these from GitHub.\n",
        "\n",
        "You could use any review data you wanted in this step - just be careful to make sure your metadata is aligned with your choice."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vbbSIGtzX3dS",
        "outputId": "0ce6514e-2479-4001-af24-824f987ce599"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--2025-03-04 09:07:26--  https://raw.githubusercontent.com/AI-Maker-Space/DataRepository/main/jw1.csv\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.110.133, 185.199.111.133, 185.199.108.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.110.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 19628 (19K) [text/plain]\n",
            "Saving to: ‘john_wick_1.csv’\n",
            "\n",
            "john_wick_1.csv     100%[===================>]  19.17K  82.8KB/s    in 0.2s    \n",
            "\n",
            "2025-03-04 09:07:26 (82.8 KB/s) - ‘john_wick_1.csv’ saved [19628/19628]\n",
            "\n",
            "--2025-03-04 09:07:27--  https://raw.githubusercontent.com/AI-Maker-Space/DataRepository/main/jw2.csv\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.110.133, 185.199.111.133, 185.199.108.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.110.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 14747 (14K) [text/plain]\n",
            "Saving to: ‘john_wick_2.csv’\n",
            "\n",
            "john_wick_2.csv     100%[===================>]  14.40K  --.-KB/s    in 0.008s  \n",
            "\n",
            "2025-03-04 09:07:27 (1.79 MB/s) - ‘john_wick_2.csv’ saved [14747/14747]\n",
            "\n",
            "--2025-03-04 09:07:28--  https://raw.githubusercontent.com/AI-Maker-Space/DataRepository/main/jw3.csv\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.109.133, 185.199.110.133, 185.199.111.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.109.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 13888 (14K) [text/plain]\n",
            "Saving to: ‘john_wick_3.csv’\n",
            "\n",
            "john_wick_3.csv     100%[===================>]  13.56K  --.-KB/s    in 0.06s   \n",
            "\n",
            "2025-03-04 09:07:28 (245 KB/s) - ‘john_wick_3.csv’ saved [13888/13888]\n",
            "\n",
            "--2025-03-04 09:07:28--  https://raw.githubusercontent.com/AI-Maker-Space/DataRepository/main/jw4.csv\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.111.133, 185.199.108.133, 185.199.109.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.111.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 15109 (15K) [text/plain]\n",
            "Saving to: ‘john_wick_4.csv’\n",
            "\n",
            "john_wick_4.csv     100%[===================>]  14.75K  --.-KB/s    in 0s      \n",
            "\n",
            "2025-03-04 09:07:29 (44.5 MB/s) - ‘john_wick_4.csv’ saved [15109/15109]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "!wget https://raw.githubusercontent.com/AI-Maker-Space/DataRepository/main/jw1.csv -O john_wick_1.csv\n",
        "!wget https://raw.githubusercontent.com/AI-Maker-Space/DataRepository/main/jw2.csv -O john_wick_2.csv\n",
        "!wget https://raw.githubusercontent.com/AI-Maker-Space/DataRepository/main/jw3.csv -O john_wick_3.csv\n",
        "!wget https://raw.githubusercontent.com/AI-Maker-Space/DataRepository/main/jw4.csv -O john_wick_4.csv"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A92NC2QZzCsi"
      },
      "source": [
        "### Data Preparation\n",
        "\n",
        "We want to make sure all our documents have the relevant metadata for the various retrieval strategies we're going to be applying today.\n",
        "\n",
        "- Self-Query: Wants as much metadata as we can provide\n",
        "- Time-weighted: Wants temporal data\n",
        "\n",
        "> NOTE: While we're creating a temporal relationship based on when these movies came out for illustrative purposes, it needs to be clear that the \"time-weighting\" in the Time-weighted Retriever is based on when the document was *accessed* last - not when it was created."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "GshBjVRJZ6p8"
      },
      "outputs": [],
      "source": [
        "from langchain_community.document_loaders.csv_loader import CSVLoader\n",
        "from datetime import datetime, timedelta\n",
        "\n",
        "documents = []\n",
        "\n",
        "for i in range(1, 5):\n",
        "  loader = CSVLoader(\n",
        "      file_path=f\"john_wick_{i}.csv\",\n",
        "      metadata_columns=[\"Review_Date\", \"Review_Title\", \"Review_Url\", \"Author\", \"Rating\"]\n",
        "  )\n",
        "\n",
        "  movie_docs = loader.load()\n",
        "  for doc in movie_docs:\n",
        "\n",
        "    # Add the \"Movie Title\" (John Wick 1, 2, ...)\n",
        "    doc.metadata[\"Movie_Title\"] = f\"John Wick {i}\"\n",
        "\n",
        "    # convert \"Rating\" to an `int`, if no rating is provided - assume 0 rating\n",
        "    doc.metadata[\"Rating\"] = int(doc.metadata[\"Rating\"]) if doc.metadata[\"Rating\"] else 0\n",
        "\n",
        "    # newer movies have a more recent \"last_accessed_at\"\n",
        "    doc.metadata[\"last_accessed_at\"] = datetime.now() - timedelta(days=4-i)\n",
        "\n",
        "  documents.extend(movie_docs)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9gQphb6y0C0S"
      },
      "source": [
        "Let's look at an example document to see if everything worked as expected!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PkUkCf7DaMiq",
        "outputId": "e90bd5da-1d87-423b-838a-cb6efc16b199"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Document(metadata={'source': 'john_wick_1.csv', 'row': 0, 'Review_Date': '6 May 2015', 'Review_Title': ' Kinetic, concise, and stylish; John Wick kicks ass.\\n', 'Review_Url': '/review/rw3233896/?ref_=tt_urv', 'Author': 'lnvicta', 'Rating': 8, 'Movie_Title': 'John Wick 1', 'last_accessed_at': datetime.datetime(2025, 3, 1, 9, 7, 31, 139811)}, page_content=\": 0\\nReview: The best way I can describe John Wick is to picture Taken but instead of Liam Neeson it's Keanu Reeves and instead of his daughter it's his dog. That's essentially the plot of the movie. John Wick (Reeves) is out to seek revenge on the people who took something he loved from him. It's a beautifully simple premise for an action movie - when action movies get convoluted, they get bad i.e. A Good Day to Die Hard. John Wick gives the viewers what they want: Awesome action, stylish stunts, kinetic chaos, and a relatable hero to tie it all together. John Wick succeeds in its simplicity.\")"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "documents[0]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lWaQpdHl0Gzc"
      },
      "source": [
        "## Task 3: Setting up QDrant!\n",
        "\n",
        "Now that we have our documents, let's create a QDrant VectorStore with the collection name \"JohnWick\".\n",
        "\n",
        "We'll leverage OpenAI's [`text-embedding-3-small`](https://openai.com/blog/new-embedding-models-and-api-updates) because it's a very powerful (and low-cost) embedding model.\n",
        "\n",
        "> NOTE: We'll be creating additional vectorstores where necessary, but this pattern is still extremely useful."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "NT8ihRJbYmMT"
      },
      "outputs": [],
      "source": [
        "from langchain_community.vectorstores import Qdrant\n",
        "from langchain_openai import OpenAIEmbeddings\n",
        "\n",
        "embeddings = OpenAIEmbeddings(model=\"text-embedding-3-small\")\n",
        "\n",
        "vectorstore = Qdrant.from_documents(\n",
        "    documents,\n",
        "    embeddings,\n",
        "    location=\":memory:\",\n",
        "    collection_name=\"JohnWick\"\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-x2SS4Rh0hiN"
      },
      "source": [
        "## Task 4: Naive RAG Chain\n",
        "\n",
        "Since we're focusing on the \"R\" in RAG today - we'll create our Retriever first."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NEH7X5Ai08FH"
      },
      "source": [
        "### R - Retrieval\n",
        "\n",
        "This naive retriever will simply look at each review as a document, and use cosine-similarity to fetch the 10 most relevant documents.\n",
        "\n",
        "> NOTE: We're choosing `10` as our `k` here to provide enough documents for our reranking process later"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "GFDPrNBtb72o"
      },
      "outputs": [],
      "source": [
        "naive_retriever = vectorstore.as_retriever(search_kwargs={\"k\" : 10})"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MbBhyQjz06dx"
      },
      "source": [
        "### A - Augmented\n",
        "\n",
        "We're going to go with a standard prompt for our simple RAG chain today! Nothing fancy here, we want this to mostly be about the Retrieval process."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "7uSz-Dbqcoki"
      },
      "outputs": [],
      "source": [
        "from langchain_core.prompts import ChatPromptTemplate\n",
        "\n",
        "RAG_TEMPLATE = \"\"\"\\\n",
        "You are a helpful and kind assistant. Use the context provided below to answer the question.\n",
        "\n",
        "If you do not know the answer, or are unsure, say you don't know.\n",
        "\n",
        "Query:\n",
        "{question}\n",
        "\n",
        "Context:\n",
        "{context}\n",
        "\"\"\"\n",
        "\n",
        "rag_prompt = ChatPromptTemplate.from_template(RAG_TEMPLATE)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BlRzpb231GGJ"
      },
      "source": [
        "### G - Generation\n",
        "\n",
        "We're going to leverage `gpt-3.5-turbo` as our LLM today, as - again - we want this to largely be about the Retrieval process."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "c-1t9H60dJLg"
      },
      "outputs": [],
      "source": [
        "from langchain_openai import ChatOpenAI\n",
        "# Changed to model with larger token limit to prevent errors when invoking some retriever chains\n",
        "chat_model = ChatOpenAI(model=\"gpt-4o-mini\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mg3QRGzA1M2x"
      },
      "source": [
        "### LCEL RAG Chain\n",
        "\n",
        "We're going to use LCEL to construct our chain.\n",
        "\n",
        "> NOTE: This chain will be exactly the same across the various examples with the exception of our Retriever!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "0bvstS7mdOW3"
      },
      "outputs": [],
      "source": [
        "from langchain_core.runnables import RunnablePassthrough\n",
        "from operator import itemgetter\n",
        "from langchain_core.output_parsers import StrOutputParser\n",
        "\n",
        "naive_retrieval_chain = (\n",
        "    # INVOKE CHAIN WITH: {\"question\" : \"<<SOME USER QUESTION>>\"}\n",
        "    # \"question\" : populated by getting the value of the \"question\" key\n",
        "    # \"context\"  : populated by getting the value of the \"question\" key and chaining it into the base_retriever\n",
        "    {\"context\": itemgetter(\"question\") | naive_retriever, \"question\": itemgetter(\"question\")}\n",
        "    # \"context\"  : is assigned to a RunnablePassthrough object (will not be called or considered in the next step)\n",
        "    #              by getting the value of the \"context\" key from the previous step\n",
        "    | RunnablePassthrough.assign(context=itemgetter(\"context\"))\n",
        "    # \"response\" : the \"context\" and \"question\" values are used to format our prompt object and then piped\n",
        "    #              into the LLM and stored in a key called \"response\"\n",
        "    # \"context\"  : populated by getting the value of the \"context\" key from the previous step\n",
        "    | {\"response\": rag_prompt | chat_model, \"context\": itemgetter(\"context\")}\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "izKujhNb1ZG8"
      },
      "source": [
        "Let's see how this simple chain does on a few different prompts.\n",
        "\n",
        "> NOTE: You might think that we've cherry picked prompts that showcase the individual skill of each of the retrieval strategies - you'd be correct!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "LI-5ueEddku9",
        "outputId": "7f3cec18-5f4e-41bb-cf71-51ba0be5388e"
      },
      "outputs": [],
      "source": [
        "# naive_retrieval_chain.invoke({\"question\" : \"Did people generally like John Wick?\"})[\"response\"].content"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "43zdcdUydtXh",
        "outputId": "db874e67-f568-4ed1-b863-b7c17b387052"
      },
      "outputs": [],
      "source": [
        "# naive_retrieval_chain.invoke({\"question\" : \"Do any reviews have a rating of 10? If so - can I have the URLs to those reviews?\"})[\"response\"].content"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "id": "lpG6rlvvvKFq",
        "outputId": "a1b330b0-628e-41be-d829-9c1d55e781f5"
      },
      "outputs": [],
      "source": [
        "# naive_retrieval_chain.invoke({\"question\" : \"What happened in John Wick?\"})[\"response\"].content"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jsbfQmbr1leg"
      },
      "source": [
        "Overall, this is not bad! Let's see if we can make it better!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ft1vt8HPR16w"
      },
      "source": [
        "## Task 5: Best-Matching 25 (BM25) Retriever\n",
        "\n",
        "Taking a step back in time - [BM25](https://www.nowpublishers.com/article/Details/INR-019) is based on [Bag-Of-Words](https://en.wikipedia.org/wiki/Bag-of-words_model) which is a sparse representation of text.\n",
        "\n",
        "In essence, it's a way to compare how similar two pieces of text are based on the words they both contain.\n",
        "\n",
        "This retriever is very straightforward to set-up! Let's see it happen down below!\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "qdF4wuj5R-cG"
      },
      "outputs": [],
      "source": [
        "from langchain_community.retrievers import BM25Retriever\n",
        "\n",
        "bm25_retriever = BM25Retriever.from_documents(documents)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KIjJlBQ8drKH"
      },
      "source": [
        "We'll construct the same chain - only changing the retriever."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "WR15EQG7SLuw"
      },
      "outputs": [],
      "source": [
        "bm25_retrieval_chain = (\n",
        "    {\"context\": itemgetter(\"question\") | bm25_retriever, \"question\": itemgetter(\"question\")}\n",
        "    | RunnablePassthrough.assign(context=itemgetter(\"context\"))\n",
        "    | {\"response\": rag_prompt | chat_model, \"context\": itemgetter(\"context\")}\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0Gi-yXCDdvJk"
      },
      "source": [
        "Let's look at the responses!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "id": "oY9qzmm3SOrF",
        "outputId": "4d4f450f-5978-460f-f242-b32407868353"
      },
      "outputs": [],
      "source": [
        "# bm25_retrieval_chain.invoke({\"question\" : \"Did people generally like John Wick?\"})[\"response\"].content"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "igfinyneSQkh",
        "outputId": "9752d4a9-dd16-45b1-f63f-a76e93a05eb3"
      },
      "outputs": [],
      "source": [
        "# bm25_retrieval_chain.invoke({\"question\" : \"Do any reviews have a rating of 10? If so - can I have the URLs to those reviews?\"})[\"response\"].content"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "id": "w0H7pV_USSMQ",
        "outputId": "bdead654-3109-4143-9a30-e1d6ca8dc534"
      },
      "outputs": [],
      "source": [
        "# bm25_retrieval_chain.invoke({\"question\" : \"What happened in John Wick?\"})[\"response\"].content"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zvg5xHaUdxCl"
      },
      "source": [
        "It's not clear that this is better or worse - but the `I don't know` isn't great!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q-dcbFn2vpZF"
      },
      "source": [
        "## Task 6: Contextual Compression (Using Reranking)\n",
        "\n",
        "Contextual Compression is a fairly straightforward idea: We want to \"compress\" our retrieved context into just the most useful bits.\n",
        "\n",
        "There are a few ways we can achieve this - but we're going to look at a specific example called reranking.\n",
        "\n",
        "The basic idea here is this:\n",
        "\n",
        "- We retrieve lots of documents that are very likely related to our query vector\n",
        "- We \"compress\" those documents into a smaller set of *more* related documents using a reranking algorithm.\n",
        "\n",
        "We'll be leveraging Cohere's Rerank model for our reranker today!\n",
        "\n",
        "All we need to do is the following:\n",
        "\n",
        "- Create a basic retriever\n",
        "- Create a compressor (reranker, in this case)\n",
        "\n",
        "That's it!\n",
        "\n",
        "Let's see it in the code below!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "psHvO2K1v_ZQ"
      },
      "outputs": [],
      "source": [
        "from langchain.retrievers.contextual_compression import ContextualCompressionRetriever\n",
        "from langchain_cohere import CohereRerank\n",
        "\n",
        "compressor = CohereRerank(model=\"rerank-english-v3.0\")\n",
        "compression_retriever = ContextualCompressionRetriever(\n",
        "    base_compressor=compressor, base_retriever=naive_retriever\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_TA9RB2x-j7P"
      },
      "source": [
        "Let's create our chain again, and see how this does!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "1BXqmxvHwX6T"
      },
      "outputs": [],
      "source": [
        "contextual_compression_retrieval_chain = (\n",
        "    {\"context\": itemgetter(\"question\") | compression_retriever, \"question\": itemgetter(\"question\")}\n",
        "    | RunnablePassthrough.assign(context=itemgetter(\"context\"))\n",
        "    | {\"response\": rag_prompt | chat_model, \"context\": itemgetter(\"context\")}\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "V3iGpokswcBb",
        "outputId": "f15d2aa1-5e8b-417d-f623-eb835d072e59"
      },
      "outputs": [],
      "source": [
        "# contextual_compression_retrieval_chain.invoke({\"question\" : \"Did people generally like John Wick?\"})[\"response\"].content"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "id": "7u_k0i4OweUd",
        "outputId": "be5fccc8-2352-4189-c524-bbeaa28cf799"
      },
      "outputs": [],
      "source": [
        "# contextual_compression_retrieval_chain.invoke({\"question\" : \"Do any reviews have a rating of 10? If so - can I have the URLs to those reviews?\"})[\"response\"].content"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "id": "zn1EqaGqweXN",
        "outputId": "42bc5972-4164-46eb-f49d-4272f39bb89b"
      },
      "outputs": [],
      "source": [
        "# contextual_compression_retrieval_chain.invoke({\"question\" : \"What happened in John Wick?\"})[\"response\"].content"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OEbT0g2S-mZ4"
      },
      "source": [
        "We'll need to rely on something like Ragas to help us get a better sense of how this is performing overall - but it \"feels\" better!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qqbghrBEQNn5"
      },
      "source": [
        "## Task 7: Multi-Query Retriever\n",
        "\n",
        "Typically in RAG we have a single query - the one provided by the user.\n",
        "\n",
        "What if we had....more than one query!\n",
        "\n",
        "In essence, a Multi-Query Retriever works by:\n",
        "\n",
        "1. Taking the original user query and creating `n` number of new user queries using an LLM.\n",
        "2. Retrieving documents for each query.\n",
        "3. Using all unique retrieved documents as context\n",
        "\n",
        "So, how is it to set-up? Not bad! Let's see it down below!\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "pfM26ReXQjzU"
      },
      "outputs": [],
      "source": [
        "from langchain.retrievers.multi_query import MultiQueryRetriever\n",
        "\n",
        "multi_query_retriever = MultiQueryRetriever.from_llm(\n",
        "    retriever=naive_retriever, llm=chat_model\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "1vRc129jQ5WW"
      },
      "outputs": [],
      "source": [
        "multi_query_retrieval_chain = (\n",
        "    {\"context\": itemgetter(\"question\") | multi_query_retriever, \"question\": itemgetter(\"question\")}\n",
        "    | RunnablePassthrough.assign(context=itemgetter(\"context\"))\n",
        "    | {\"response\": rag_prompt | chat_model, \"context\": itemgetter(\"context\")}\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "id": "CGgNuOb3Q3M9",
        "outputId": "c5273ecf-da35-40b8-fbdb-0f8beab425f7"
      },
      "outputs": [],
      "source": [
        "# multi_query_retrieval_chain.invoke({\"question\" : \"Did people generally like John Wick?\"})[\"response\"].content"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "aAlSthxrRDBC",
        "outputId": "230ff807-23ae-4d25-8d11-cfdbed0b77cb"
      },
      "outputs": [],
      "source": [
        "# multi_query_retrieval_chain.invoke({\"question\" : \"Do any reviews have a rating of 10? If so - can I have the URLs to those reviews?\"})[\"response\"].content"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 88
        },
        "id": "Uv1mpCK8REs4",
        "outputId": "00fbc22a-ed9b-4613-9695-0b179e3f8369"
      },
      "outputs": [],
      "source": [
        "# multi_query_retrieval_chain.invoke({\"question\" : \"What happened in John Wick?\"})[\"response\"].content"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EDEawBf_d_3G"
      },
      "source": [
        "## Task 8: Parent Document Retriever\n",
        "\n",
        "A \"small-to-big\" strategy - the Parent Document Retriever works based on a simple strategy:\n",
        "\n",
        "1. Each un-split \"document\" will be designated as a \"parent document\" (You could use larger chunks of document as well, but our data format allows us to consider the overall document as the parent chunk)\n",
        "2. Store those \"parent documents\" in a memory store (not a VectorStore)\n",
        "3. We will chunk each of those documents into smaller documents, and associate them with their respective parents, and store those in a VectorStore. We'll call those \"child chunks\".\n",
        "4. When we query our Retriever, we will do a similarity search comparing our query vector to the \"child chunks\".\n",
        "5. Instead of returning the \"child chunks\", we'll return their associated \"parent chunks\".\n",
        "\n",
        "Okay, maybe that was a few steps - but the basic idea is this:\n",
        "\n",
        "- Search for small documents\n",
        "- Return big documents\n",
        "\n",
        "The intuition is that we're likely to find the most relevant information by limiting the amount of semantic information that is encoded in each embedding vector - but we're likely to miss relevant surrounding context if we only use that information.\n",
        "\n",
        "Let's start by creating our \"parent documents\" and defining a `RecursiveCharacterTextSplitter`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "qJ53JJuMd_ZH"
      },
      "outputs": [],
      "source": [
        "from langchain.retrievers import ParentDocumentRetriever\n",
        "from langchain.storage import InMemoryStore\n",
        "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
        "from qdrant_client import QdrantClient, models\n",
        "\n",
        "parent_docs = documents\n",
        "child_splitter = RecursiveCharacterTextSplitter(chunk_size=200)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oOpXfVUH3gL3"
      },
      "source": [
        "We'll need to set up a new QDrant vectorstore - and we'll use another useful pattern to do so!\n",
        "\n",
        "> NOTE: We are manually defining our embedding dimension, you'll need to change this if you're using a different embedding model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rzFc-_9HlGQ-",
        "outputId": "223662dd-c36f-42f7-d1b0-b086e571484e"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/tmp/ipykernel_501966/3574430551.py:8: LangChainDeprecationWarning: The class `Qdrant` was deprecated in LangChain 0.0.37 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-qdrant package and should be used instead. To use it run `pip install -U :class:`~langchain-qdrant` and import as `from :class:`~langchain_qdrant import Qdrant``.\n",
            "  parent_document_vectorstore = Qdrant(\n"
          ]
        }
      ],
      "source": [
        "client = QdrantClient(location=\":memory:\")\n",
        "\n",
        "client.create_collection(\n",
        "    collection_name=\"full_documents\",\n",
        "    vectors_config=models.VectorParams(size=1536, distance=models.Distance.COSINE)\n",
        ")\n",
        "\n",
        "parent_document_vectorstore = Qdrant(\n",
        "    collection_name=\"full_documents\", embeddings=OpenAIEmbeddings(model=\"text-embedding-3-small\"), client=client\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sf_g95FA3s6w"
      },
      "source": [
        "Now we can create our `InMemoryStore` that will hold our \"parent documents\" - and build our retriever!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "id": "BpWVjPf4fLUp"
      },
      "outputs": [],
      "source": [
        "store = InMemoryStore()\n",
        "\n",
        "parent_document_retriever = ParentDocumentRetriever(\n",
        "    vectorstore = parent_document_vectorstore,\n",
        "    docstore=store,\n",
        "    child_splitter=child_splitter,\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KoYmSWfE32Zo"
      },
      "source": [
        "By default, this is empty as we haven't added any documents - let's add some now!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "id": "iQ2ZzfKigMZc"
      },
      "outputs": [],
      "source": [
        "parent_document_retriever.add_documents(parent_docs, ids=None)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bI7Tip1335rE"
      },
      "source": [
        "We'll create the same chain we did before - but substitute our new `parent_document_retriever`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "id": "Qq_adt2KlSqp"
      },
      "outputs": [],
      "source": [
        "parent_document_retrieval_chain = (\n",
        "    {\"context\": itemgetter(\"question\") | parent_document_retriever, \"question\": itemgetter(\"question\")}\n",
        "    | RunnablePassthrough.assign(context=itemgetter(\"context\"))\n",
        "    | {\"response\": rag_prompt | chat_model, \"context\": itemgetter(\"context\")}\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jNolUVQb4Apt"
      },
      "source": [
        "Let's give it a whirl!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "id": "TXB5i89Zly5W",
        "outputId": "94c240be-7c5b-4c58-9eee-56d93285a054"
      },
      "outputs": [],
      "source": [
        "# parent_document_retrieval_chain.invoke({\"question\" : \"Did people generally like John Wick?\"})[\"response\"].content"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "V5F1T-wNl3cg",
        "outputId": "9b81e72e-5db7-4b8a-b25b-400ea0df5335"
      },
      "outputs": [],
      "source": [
        "# parent_document_retrieval_chain.invoke({\"question\" : \"Do any reviews have a rating of 10? If so - can I have the URLs to those reviews?\"})[\"response\"].content"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "id": "ZqARszGzvGcG",
        "outputId": "8867f83c-db13-4db4-d57f-9bd51d32cd8a"
      },
      "outputs": [],
      "source": [
        "# parent_document_retrieval_chain.invoke({\"question\" : \"What happened in John Wick?\"})[\"response\"].content"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B41cj42s4DPM"
      },
      "source": [
        "Overall, the performance *seems* largely the same. We can leverage a tool like [Ragas]() to more effectively answer the question about the performance."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VUrIBKl_TwS9"
      },
      "source": [
        "## Task 9: Ensemble Retriever\n",
        "\n",
        "In brief, an Ensemble Retriever simply takes 2, or more, retrievers and combines their retrieved documents based on a rank-fusion algorithm.\n",
        "\n",
        "In this case - we're using the [Reciprocal Rank Fusion](https://plg.uwaterloo.ca/~gvcormac/cormacksigir09-rrf.pdf) algorithm.\n",
        "\n",
        "Setting it up is as easy as providing a list of our desired retrievers - and the weights for each retriever."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "id": "8j7jpZsKTxic"
      },
      "outputs": [],
      "source": [
        "from langchain.retrievers import EnsembleRetriever\n",
        "\n",
        "retriever_list = [bm25_retriever, naive_retriever, parent_document_retriever, compression_retriever, multi_query_retriever]\n",
        "equal_weighting = [1/len(retriever_list)] * len(retriever_list)\n",
        "\n",
        "ensemble_retriever = EnsembleRetriever(\n",
        "    retrievers=retriever_list, weights=equal_weighting\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kpo9Psl5hhJ-"
      },
      "source": [
        "We'll pack *all* of these retrievers together in an ensemble."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "id": "KZ__EZwpUKkd"
      },
      "outputs": [],
      "source": [
        "ensemble_retrieval_chain = (\n",
        "    {\"context\": itemgetter(\"question\") | ensemble_retriever, \"question\": itemgetter(\"question\")}\n",
        "    | RunnablePassthrough.assign(context=itemgetter(\"context\"))\n",
        "    | {\"response\": rag_prompt | chat_model, \"context\": itemgetter(\"context\")}\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SSsvHpRMj24L"
      },
      "source": [
        "Let's look at our results!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "id": "0lMvqL88UQI-",
        "outputId": "d86dd5f7-0a13-4836-c0ce-cc4c431fd889"
      },
      "outputs": [],
      "source": [
        "# ensemble_retrieval_chain.invoke({\"question\" : \"Did people generally like John Wick?\"})[\"response\"].content"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "id": "MNFWLYECURI1",
        "outputId": "b17973b5-66a9-4481-97d5-880b5754b5c5"
      },
      "outputs": [],
      "source": [
        "# ensemble_retrieval_chain.invoke({\"question\" : \"Do any reviews have a rating of 10? If so - can I have the URLs to those reviews?\"})[\"response\"].content"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 88
        },
        "id": "A7qbHfWgUR4c",
        "outputId": "f7373144-59ef-4fc7-b75d-ca00e7df881e"
      },
      "outputs": [],
      "source": [
        "# ensemble_retrieval_chain.invoke({\"question\" : \"What happened in John Wick?\"})[\"response\"].content"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MopbkNJAXVaN"
      },
      "source": [
        "## Task 10: Semantic Chunking\n",
        "\n",
        "While this is not a retrieval method - it *is* an effective way of increasing retrieval performance on corpora that have clean semantic breaks in them.\n",
        "\n",
        "Essentially, Semantic Chunking is implemented by:\n",
        "\n",
        "1. Embedding all sentences in the corpus.\n",
        "2. Combining or splitting sequences of sentences based on their semantic similarity based on a number of [possible thresholding methods](https://python.langchain.com/docs/how_to/semantic-chunker/):\n",
        "  - `percentile`\n",
        "  - `standard_deviation`\n",
        "  - `interquartile`\n",
        "  - `gradient`\n",
        "3. Each sequence of related sentences is kept as a document!\n",
        "\n",
        "Let's see how to implement this!\n",
        "\n",
        "> NOTE: You do not need to run this cell if you're running this locally"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1dHeB-yGXneL",
        "outputId": "efc59105-518a-4134-9228-d98b8a97e08e"
      },
      "outputs": [],
      "source": [
        "#!pip install -qU langchain_experimental"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U9ciZbFEldv_"
      },
      "source": [
        "We'll use the `percentile` thresholding method for this example which will:\n",
        "\n",
        "Calculate all distances between sentences, and then break apart sequences of setences that exceed a given percentile among all distances."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {
        "id": "66EIEWiEYl5y"
      },
      "outputs": [],
      "source": [
        "from langchain_experimental.text_splitter import SemanticChunker\n",
        "\n",
        "semantic_chunker = SemanticChunker(\n",
        "    embeddings,\n",
        "    breakpoint_threshold_type=\"percentile\"\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YqoKmz12mhRW"
      },
      "source": [
        "Now we can split our documents."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {
        "id": "ROcV7o68ZIq7"
      },
      "outputs": [],
      "source": [
        "semantic_documents = semantic_chunker.split_documents(documents)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L8-LNC-Xmjex"
      },
      "source": [
        "Let's create a new vector store."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {
        "id": "h3sl9QjyZhIe"
      },
      "outputs": [],
      "source": [
        "semantic_vectorstore = Qdrant.from_documents(\n",
        "    semantic_documents,\n",
        "    embeddings,\n",
        "    location=\":memory:\",\n",
        "    collection_name=\"JohnWickSemantic\"\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Eh_r_-LHmmKn"
      },
      "source": [
        "We'll use naive retrieval for this example."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {
        "id": "odVyDUHwZftc"
      },
      "outputs": [],
      "source": [
        "semantic_retriever = semantic_vectorstore.as_retriever(search_kwargs={\"k\" : 10})"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Mkeiv_ojmp6G"
      },
      "source": [
        "Finally we can create our classic chain!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {
        "id": "xWE_0J0mZveG"
      },
      "outputs": [],
      "source": [
        "semantic_retrieval_chain = (\n",
        "    {\"context\": itemgetter(\"question\") | semantic_retriever, \"question\": itemgetter(\"question\")}\n",
        "    | RunnablePassthrough.assign(context=itemgetter(\"context\"))\n",
        "    | {\"response\": rag_prompt | chat_model, \"context\": itemgetter(\"context\")}\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R5pfjLQ3ms9_"
      },
      "source": [
        "And view the results!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "id": "0lN2j-e4Z0SD",
        "outputId": "ef483e21-7200-4dfc-b8bf-aed4f23587b2"
      },
      "outputs": [],
      "source": [
        "# semantic_retrieval_chain.invoke({\"question\" : \"Did people generally like John Wick?\"})[\"response\"].content"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "id": "xdqfBH1SZ3f9",
        "outputId": "ed62b2d1-7586-46cc-aaf4-c54192a56155"
      },
      "outputs": [],
      "source": [
        "# semantic_retrieval_chain.invoke({\"question\" : \"Do any reviews have a rating of 10? If so - can I have the URLs to those reviews?\"})[\"response\"].content"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "id": "rAcAObZnZ4o6",
        "outputId": "3f1cade3-41e4-4e42-ef71-048dd18e5e3a"
      },
      "outputs": [],
      "source": [
        "# semantic_retrieval_chain.invoke({\"question\" : \"What happened in John Wick?\"})[\"response\"].content"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xk2n3-pnVWDJ"
      },
      "source": [
        "# 🤝 Breakout Room Part #2"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2SkJLYwMVZkj"
      },
      "source": [
        "#### 🏗️ Activity #1\n",
        "\n",
        "Your task is to evaluate the various Retriever methods against eachother.\n",
        "\n",
        "You are expected to:\n",
        "\n",
        "1. Create a \"golden dataset\"\n",
        " - Use Synthetic Data Generation (powered by Ragas, or otherwise) to create this dataset\n",
        "2. Evaluate each retriever with *retriever specific* Ragas metrics\n",
        " - Semantic Chunking is not considered a retriever method and will not be required for marks, but you may find it useful to do a \"semantic chunking on\" vs. \"semantic chunking off\" comparision between them\n",
        "3. Compile these in a list and write a small paragraph about which is best for this particular data and why.\n",
        "\n",
        "Your analysis should factor in:\n",
        "  - Cost\n",
        "  - Latency\n",
        "  - Performance\n",
        "\n",
        "> NOTE: This is **NOT** required to be completed in class. Please spend time in your breakout rooms creating a plan before moving on to writing code."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TWAr16a5XMub"
      },
      "source": [
        "##### HINTS:\n",
        "\n",
        "- LangSmith provides detailed information about latency and cost."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Golden Dataset using SDG"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "e6396cd68693432d8b5da6b6d1583a7c",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Applying SummaryExtractor:   0%|          | 0/44 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "c5a3d84be2944ca0881697509202b397",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Applying CustomNodeFilter:   0%|          | 0/100 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Node a2927424-8db5-4ea9-bf61-c6f130fca3dd does not have a summary. Skipping filtering.\n",
            "Node 5631205f-34ec-42d0-93e1-5b1875d1917b does not have a summary. Skipping filtering.\n",
            "Node c3868328-b9cf-4ca0-957a-05287839a37e does not have a summary. Skipping filtering.\n",
            "Node 667dd6c0-5e90-4874-b441-dfd2d8a24697 does not have a summary. Skipping filtering.\n",
            "Node efc6062f-c030-45d4-b6eb-97789905d288 does not have a summary. Skipping filtering.\n",
            "Node c01c32d5-8fab-4296-9257-bda0eaae386c does not have a summary. Skipping filtering.\n",
            "Node b267ffd3-352f-4b56-8897-829ded8295cd does not have a summary. Skipping filtering.\n",
            "Node 3a717069-c4be-45d9-97bf-790d06de6c3e does not have a summary. Skipping filtering.\n",
            "Node 2ec92694-c119-4733-8e4c-b2282e9133cc does not have a summary. Skipping filtering.\n",
            "Node bcbbf296-08eb-410d-b2e1-1272a2f2f315 does not have a summary. Skipping filtering.\n",
            "Node feeee072-67f5-4aff-ad5b-513c61141959 does not have a summary. Skipping filtering.\n",
            "Node 9f52621e-0431-43eb-9089-98ea081c3bca does not have a summary. Skipping filtering.\n",
            "Node 6d44823e-7fd7-4e1c-8bf6-cee392fc0687 does not have a summary. Skipping filtering.\n",
            "Node 48b96de0-3f8b-4cfe-844b-998f95e007e8 does not have a summary. Skipping filtering.\n",
            "Node 593c4613-4e34-4269-9b08-296e71b783b5 does not have a summary. Skipping filtering.\n",
            "Node b1b7aff6-b8a0-4eaf-8841-d9d809cb8dca does not have a summary. Skipping filtering.\n",
            "Node 7331d4ff-2f3e-4413-8319-ffb12cc11e0c does not have a summary. Skipping filtering.\n",
            "Node 0d151d57-48e2-42cd-b4d7-7166493ad354 does not have a summary. Skipping filtering.\n",
            "Node a2d6a011-098a-4bd0-a9b1-a6b41e76411d does not have a summary. Skipping filtering.\n",
            "Node 96ed0be9-ea05-417b-ab73-de9b3f82c2d9 does not have a summary. Skipping filtering.\n",
            "Node ed17365f-2450-4fd3-8141-56bed70721e6 does not have a summary. Skipping filtering.\n",
            "Node 3fa7856e-1c84-4188-9105-e011235ff639 does not have a summary. Skipping filtering.\n",
            "Node 9c356171-1edd-4169-85d3-cf1f3f3e456c does not have a summary. Skipping filtering.\n",
            "Node dce5fc2f-b7e5-432e-8a03-64d01810eb1f does not have a summary. Skipping filtering.\n",
            "Node 953011ac-157f-4ae2-aabe-2f2d4b427788 does not have a summary. Skipping filtering.\n",
            "Node 257a0d43-3697-49ba-8134-3a607d574d66 does not have a summary. Skipping filtering.\n",
            "Node 43799682-f8ec-467f-804c-efbb225102d9 does not have a summary. Skipping filtering.\n",
            "Node daa674b7-eb67-40dd-87a4-6c707897c3f7 does not have a summary. Skipping filtering.\n",
            "Node 61dd0998-4876-491a-a76c-21a2a001bcec does not have a summary. Skipping filtering.\n",
            "Node c3ca15f2-d44f-49ad-8ec7-7f940ce573bf does not have a summary. Skipping filtering.\n",
            "Node ea617206-bece-44dc-9636-3dbc5b20a77d does not have a summary. Skipping filtering.\n",
            "Node ad955e18-1aec-4f5a-9516-12b66d595ca4 does not have a summary. Skipping filtering.\n",
            "Node b9b9d0f0-d7ab-442d-8472-279083bea4ea does not have a summary. Skipping filtering.\n",
            "Node e71595b3-f1b1-4bbd-9c5e-3517246dc974 does not have a summary. Skipping filtering.\n",
            "Node af4626d8-768e-4f01-bbfa-de1612c28780 does not have a summary. Skipping filtering.\n",
            "Node 8369d084-ca68-4549-87c2-264c690f4085 does not have a summary. Skipping filtering.\n",
            "Node 6f801789-6d43-4523-93db-ba0aaa86a4c5 does not have a summary. Skipping filtering.\n",
            "Node 8fdbf8c1-5bdc-44f1-82c5-0b61da3406b3 does not have a summary. Skipping filtering.\n",
            "Node c4f59c7d-164d-47d6-b6f4-8ffaf9a5768b does not have a summary. Skipping filtering.\n",
            "Node 97372cab-2119-438e-b137-6a158bc83be7 does not have a summary. Skipping filtering.\n",
            "Node c37af2cd-1621-4c18-8660-aed1d6265bf8 does not have a summary. Skipping filtering.\n",
            "Node c8b11457-f8e7-439d-951e-ce36c2ad9716 does not have a summary. Skipping filtering.\n",
            "Node b2bbabeb-dfa0-407b-a43c-f214f7c0f431 does not have a summary. Skipping filtering.\n",
            "Node 3c3fa88a-04b4-4e29-9183-f55554bf0cd7 does not have a summary. Skipping filtering.\n",
            "Node 3141b317-2d83-40a2-bf3d-346bb38d6c71 does not have a summary. Skipping filtering.\n",
            "Node 625a9565-268c-4f9f-a510-09c256dcb5fc does not have a summary. Skipping filtering.\n",
            "Node 25846686-11c5-4331-b8f6-c03c01343d35 does not have a summary. Skipping filtering.\n",
            "Node 64110d69-fec0-4161-80a1-dc4d604e6ba6 does not have a summary. Skipping filtering.\n",
            "Node b2f82062-cf46-4106-a654-34b8b9bbecf9 does not have a summary. Skipping filtering.\n",
            "Node 56f5b27b-3c19-4a96-bb8d-cbc691600784 does not have a summary. Skipping filtering.\n",
            "Node 05e682f1-1691-4be4-920a-2e6c1e6ba55a does not have a summary. Skipping filtering.\n",
            "Node 71306fdd-d445-47ff-b326-1575040f2baa does not have a summary. Skipping filtering.\n",
            "Node 9b1b12de-1182-45a5-935f-16c49763102f does not have a summary. Skipping filtering.\n",
            "Node a044f91f-e27e-43ac-b977-030988a7db6a does not have a summary. Skipping filtering.\n",
            "Node d1a1110b-35fb-45e8-9575-ad3311fdeba0 does not have a summary. Skipping filtering.\n",
            "Node ba9004f9-a165-4cfa-a408-7ab74cbf05b7 does not have a summary. Skipping filtering.\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "95a89825623a44bc8606dff3e90e8770",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Applying [EmbeddingExtractor, ThemesExtractor, NERExtractor]:   0%|          | 0/244 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "92e9c90bfc434eaea72172ef203a5df2",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Applying OverlapScoreBuilder:   0%|          | 0/1 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "933e92fd851f4d41961116f34c59d375",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Generating personas:   0%|          | 0/3 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "73c6ab84c4324b07b79be224703e7e63",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Generating Scenarios:   0%|          | 0/2 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "a12c2f67fd394964a58ccf57edb16c96",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Generating Samples:   0%|          | 0/10 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "from ragas.llms import LangchainLLMWrapper\n",
        "from ragas.embeddings import LangchainEmbeddingsWrapper\n",
        "from ragas.testset import TestsetGenerator\n",
        "\n",
        "generator_llm = LangchainLLMWrapper(ChatOpenAI(model=\"gpt-4o\"))\n",
        "generator_embeddings = LangchainEmbeddingsWrapper(embeddings)\n",
        "\n",
        "generator = TestsetGenerator(llm=generator_llm, embedding_model=generator_embeddings)\n",
        "golden_dataset = generator.generate_with_langchain_docs(documents, testset_size=10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>user_input</th>\n",
              "      <th>reference_contexts</th>\n",
              "      <th>reference</th>\n",
              "      <th>synthesizer_name</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>What makes John Wick a standout action movie a...</td>\n",
              "      <td>[: 0\\nReview: The best way I can describe John...</td>\n",
              "      <td>John Wick is described as a standout action mo...</td>\n",
              "      <td>single_hop_specifc_query_synthesizer</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Wut makes Jon Wick so popular among action mov...</td>\n",
              "      <td>[: 2\\nReview: With the fourth installment scor...</td>\n",
              "      <td>The fourth installment of John Wick scored imm...</td>\n",
              "      <td>single_hop_specifc_query_synthesizer</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>What makes Chad Stahelski's direction in John ...</td>\n",
              "      <td>[: 3\\nReview: John wick has a very simple reve...</td>\n",
              "      <td>Chad Stahelski's direction in John Wick stands...</td>\n",
              "      <td>single_hop_specifc_query_synthesizer</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>What role do Russian mobsters play in the movi...</td>\n",
              "      <td>[: 4\\nReview: Though he no longer has a taste ...</td>\n",
              "      <td>In the movie John Wick, Russian mobsters are r...</td>\n",
              "      <td>single_hop_specifc_query_synthesizer</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>How does the Russian mob prince contribute to ...</td>\n",
              "      <td>[: 5\\nReview: Ultra-violent first entry with l...</td>\n",
              "      <td>In John Wick (2014), the Russian mob prince pl...</td>\n",
              "      <td>single_hop_specifc_query_synthesizer</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>So like, how's Keanu Reeves doin' in that movi...</td>\n",
              "      <td>[&lt;1-hop&gt;\\n\\n: 24\\nReview: Predictable, juvenil...</td>\n",
              "      <td>In the movie, Keanu Reeves mumbles his way thr...</td>\n",
              "      <td>multi_hop_specific_query_synthesizer</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>How does John Wick's battle against the Russia...</td>\n",
              "      <td>[&lt;1-hop&gt;\\n\\n: 20\\nReview: John Wick is somethi...</td>\n",
              "      <td>John Wick's battle against the Russian Mafia i...</td>\n",
              "      <td>multi_hop_specific_query_synthesizer</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>How does 'John Wick: Chapter 3 - Parabellum' e...</td>\n",
              "      <td>[&lt;1-hop&gt;\\n\\n: 24\\nReview: John Wick: Chapter 3...</td>\n",
              "      <td>'John Wick: Chapter 3 - Parabellum' explores t...</td>\n",
              "      <td>multi_hop_specific_query_synthesizer</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>How do the reviews of 'John Wick: Chapter 4' d...</td>\n",
              "      <td>[&lt;1-hop&gt;\\n\\n: 24\\nReview: John Wick: Chapter 4...</td>\n",
              "      <td>The reviews of 'John Wick: Chapter 4' differ s...</td>\n",
              "      <td>multi_hop_specific_query_synthesizer</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>In what ways does the film 'John Wick' stand o...</td>\n",
              "      <td>[&lt;1-hop&gt;\\n\\n: 3\\nReview: John wick has a very ...</td>\n",
              "      <td>The film 'John Wick' stands out in the action ...</td>\n",
              "      <td>multi_hop_specific_query_synthesizer</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                          user_input  \\\n",
              "0  What makes John Wick a standout action movie a...   \n",
              "1  Wut makes Jon Wick so popular among action mov...   \n",
              "2  What makes Chad Stahelski's direction in John ...   \n",
              "3  What role do Russian mobsters play in the movi...   \n",
              "4  How does the Russian mob prince contribute to ...   \n",
              "5  So like, how's Keanu Reeves doin' in that movi...   \n",
              "6  How does John Wick's battle against the Russia...   \n",
              "7  How does 'John Wick: Chapter 3 - Parabellum' e...   \n",
              "8  How do the reviews of 'John Wick: Chapter 4' d...   \n",
              "9  In what ways does the film 'John Wick' stand o...   \n",
              "\n",
              "                                  reference_contexts  \\\n",
              "0  [: 0\\nReview: The best way I can describe John...   \n",
              "1  [: 2\\nReview: With the fourth installment scor...   \n",
              "2  [: 3\\nReview: John wick has a very simple reve...   \n",
              "3  [: 4\\nReview: Though he no longer has a taste ...   \n",
              "4  [: 5\\nReview: Ultra-violent first entry with l...   \n",
              "5  [<1-hop>\\n\\n: 24\\nReview: Predictable, juvenil...   \n",
              "6  [<1-hop>\\n\\n: 20\\nReview: John Wick is somethi...   \n",
              "7  [<1-hop>\\n\\n: 24\\nReview: John Wick: Chapter 3...   \n",
              "8  [<1-hop>\\n\\n: 24\\nReview: John Wick: Chapter 4...   \n",
              "9  [<1-hop>\\n\\n: 3\\nReview: John wick has a very ...   \n",
              "\n",
              "                                           reference  \\\n",
              "0  John Wick is described as a standout action mo...   \n",
              "1  The fourth installment of John Wick scored imm...   \n",
              "2  Chad Stahelski's direction in John Wick stands...   \n",
              "3  In the movie John Wick, Russian mobsters are r...   \n",
              "4  In John Wick (2014), the Russian mob prince pl...   \n",
              "5  In the movie, Keanu Reeves mumbles his way thr...   \n",
              "6  John Wick's battle against the Russian Mafia i...   \n",
              "7  'John Wick: Chapter 3 - Parabellum' explores t...   \n",
              "8  The reviews of 'John Wick: Chapter 4' differ s...   \n",
              "9  The film 'John Wick' stands out in the action ...   \n",
              "\n",
              "                       synthesizer_name  \n",
              "0  single_hop_specifc_query_synthesizer  \n",
              "1  single_hop_specifc_query_synthesizer  \n",
              "2  single_hop_specifc_query_synthesizer  \n",
              "3  single_hop_specifc_query_synthesizer  \n",
              "4  single_hop_specifc_query_synthesizer  \n",
              "5  multi_hop_specific_query_synthesizer  \n",
              "6  multi_hop_specific_query_synthesizer  \n",
              "7  multi_hop_specific_query_synthesizer  \n",
              "8  multi_hop_specific_query_synthesizer  \n",
              "9  multi_hop_specific_query_synthesizer  "
            ]
          },
          "execution_count": 54,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "golden_dataset.to_pandas()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### RAGAS Evaluation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "metadata": {},
      "outputs": [],
      "source": [
        "from ragas import EvaluationDataset, RunConfig, evaluate\n",
        "from ragas.metrics import context_precision, context_recall, context_entity_recall, answer_relevancy, faithfulness\n",
        "import pandas as pd\n",
        "import json\n",
        "\n",
        "retriever_specific_metrics = [context_precision, context_recall, context_entity_recall]\n",
        "additional_metrics = [faithfulness, answer_relevancy]\n",
        "all_metrics = retriever_specific_metrics + additional_metrics\n",
        "\n",
        "evaluator_llm = LangchainLLMWrapper(ChatOpenAI(model=\"gpt-4o\"))\n",
        "custom_run_config = RunConfig(timeout=360)\n",
        "\n",
        "def run_ragas_evaluation(retriever_chain, dataset):\n",
        "    for test_row in dataset:\n",
        "        response = retriever_chain.invoke({\"question\" : test_row.eval_sample.user_input})\n",
        "        test_row.eval_sample.response = response[\"response\"].content\n",
        "        test_row.eval_sample.retrieved_contexts = [context.page_content for context in response[\"context\"]] \n",
        "\n",
        "    evaluation_dataset = EvaluationDataset.from_pandas(dataset.to_pandas())\n",
        "\n",
        "    result = evaluate(\n",
        "        dataset=evaluation_dataset,\n",
        "        metrics=all_metrics,\n",
        "        llm=evaluator_llm,\n",
        "        run_config=custom_run_config\n",
        "    )\n",
        "\n",
        "    return result\n",
        "\n",
        "def add_results_to_df(results_df, name, result):\n",
        "    df = pd.DataFrame([{\"retriver_name\": name}])\n",
        "    df = pd.concat([df, pd.DataFrame(json.loads(f\"{result}\".replace(\"'\", '\"')), index=[0])], axis=1)\n",
        "    if results_df is None:\n",
        "        results_df = df\n",
        "    else:\n",
        "        results_df = pd.concat([results_df, df], ignore_index=True)\n",
        "    return results_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Evaluating Naive\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "fde92b31696c4c6a8f8c56a8a6a09d06",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Evaluating:   0%|          | 0/50 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'context_precision': 0.5649, 'context_recall': 0.8000, 'context_entity_recall': 0.7117, 'faithfulness': 0.8182, 'answer_relevancy': 0.9479}\n",
            "\n",
            "==================================================\n",
            "\n",
            "Evaluating BM25\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "d1eb0cab9a784ee19d8ebd0692d6a18d",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Evaluating:   0%|          | 0/50 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'context_precision': 0.4583, 'context_recall': 0.6500, 'context_entity_recall': 0.5733, 'faithfulness': 0.7171, 'answer_relevancy': 0.8544}\n",
            "\n",
            "==================================================\n",
            "\n",
            "Evaluating ContextualCompression\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Failed to send compressed multipart ingest: langsmith.utils.LangSmithError: Failed to POST https://api.smith.langchain.com/runs/multipart in LangSmith API. HTTPError('400 Client Error: Bad Request for url: https://api.smith.langchain.com/runs/multipart', '{\"error\":\"Bad request: invalid \\'dotted_order\\': dotted_order 021bbb1f-2e53-463f-9574-fbd6977efef9 has timestamp 2025-03-04 15:20:43.352662 +0000 UTC earlier than parent timestamp 2025-03-04 15:20:43.457121 +0000 UTC for run_id:021bbb1f-2e53-463f-9574-fbd6977efef9 trace_id:33e5df35-c961-48cd-8ee2-72722e1f9045 dotted_order:20250304T152043457121Z33e5df35-c961-48cd-8ee2-72722e1f9045.20250304T152043352662Z021bbb1f-2e53-463f-9574-fbd6977efef9 parent_run_id:33e5df35-c961-48cd-8ee2-72722e1f9045\"}\\n')\n",
            "Failed to send compressed multipart ingest: langsmith.utils.LangSmithError: Failed to POST https://api.smith.langchain.com/runs/multipart in LangSmith API. HTTPError('400 Client Error: Bad Request for url: https://api.smith.langchain.com/runs/multipart', '{\"error\":\"Bad request: invalid \\'dotted_order\\': dotted_order 73b47982-da7f-433c-9a1a-9ca5d99cdf33 has timestamp 2025-03-04 15:20:43.367389 +0000 UTC earlier than parent timestamp 2025-03-04 15:20:43.457121 +0000 UTC for run_id:e9068f88-0d3c-411c-a23d-9c5ae96fae55 trace_id:33e5df35-c961-48cd-8ee2-72722e1f9045 dotted_order:20250304T152043457121Z33e5df35-c961-48cd-8ee2-72722e1f9045.20250304T152043367389Z73b47982-da7f-433c-9a1a-9ca5d99cdf33.20250304T152043371479Z166055ff-704e-4cf8-8ec0-3e1d5a0298b7.20250304T152043389321Ze9068f88-0d3c-411c-a23d-9c5ae96fae55 parent_run_id:166055ff-704e-4cf8-8ec0-3e1d5a0298b7\"}\\n')\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "7f34a04663544dd697344e8ad279010d",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Evaluating:   0%|          | 0/50 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'context_precision': 0.6833, 'context_recall': 0.7667, 'context_entity_recall': 0.6600, 'faithfulness': 0.7595, 'answer_relevancy': 0.9571}\n",
            "\n",
            "==================================================\n",
            "\n",
            "Evaluating ParentDocument\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "7b624ba59bc4471d97aa4a2b325ed4a7",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Evaluating:   0%|          | 0/50 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'context_precision': 0.6083, 'context_recall': 0.7167, 'context_entity_recall': 0.5733, 'faithfulness': 0.8395, 'answer_relevancy': 0.9600}\n",
            "\n",
            "==================================================\n",
            "\n",
            "Evaluating MultiQuery\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "96564af741374c79a2362e105700795b",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Evaluating:   0%|          | 0/50 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'context_precision': 0.5970, 'context_recall': 0.8667, 'context_entity_recall': 0.6783, 'faithfulness': 0.8501, 'answer_relevancy': 0.9396}\n",
            "\n",
            "==================================================\n",
            "\n",
            "Evaluating Ensemble\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "d723a15c57a94d4a89159d3c4a2cd194",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Evaluating:   0%|          | 0/50 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'context_precision': 0.5306, 'context_recall': 0.8667, 'context_entity_recall': 0.6867, 'faithfulness': 0.8470, 'answer_relevancy': 0.9531}\n",
            "\n",
            "==================================================\n",
            "\n"
          ]
        }
      ],
      "source": [
        "retriever_chains = {\n",
        "    \"Naive\": naive_retrieval_chain,\n",
        "    \"BM25\": bm25_retrieval_chain,\n",
        "    \"ContextualCompression\": contextual_compression_retrieval_chain,\n",
        "    \"ParentDocument\": parent_document_retrieval_chain,\n",
        "    \"MultiQuery\": multi_query_retrieval_chain,\n",
        "    \"Ensemble\": ensemble_retrieval_chain,\n",
        "    # \"Semantic Chunking\": semantic_retrieval_chain\n",
        "}\n",
        "\n",
        "results_df = None\n",
        "for name, retriever_chain in retriever_chains.items():\n",
        "    print(f\"Evaluating {name}\")\n",
        "    result = run_ragas_evaluation(retriever_chain.with_config({\"run_name\": name}), golden_dataset)\n",
        "    print(result)\n",
        "    results_df = add_results_to_df(results_df, name, result)\n",
        "    print(\"\\n\" + \"=\"*50 + \"\\n\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 57,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>context_precision</th>\n",
              "      <th>context_recall</th>\n",
              "      <th>context_entity_recall</th>\n",
              "      <th>faithfulness</th>\n",
              "      <th>answer_relevancy</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>retriver_name</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>Naive</th>\n",
              "      <td>0.5649</td>\n",
              "      <td>0.8000</td>\n",
              "      <td>0.7117</td>\n",
              "      <td>0.8182</td>\n",
              "      <td>0.9479</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>BM25</th>\n",
              "      <td>0.4583</td>\n",
              "      <td>0.6500</td>\n",
              "      <td>0.5733</td>\n",
              "      <td>0.7171</td>\n",
              "      <td>0.8544</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>ContextualCompression</th>\n",
              "      <td>0.6833</td>\n",
              "      <td>0.7667</td>\n",
              "      <td>0.6600</td>\n",
              "      <td>0.7595</td>\n",
              "      <td>0.9571</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>ParentDocument</th>\n",
              "      <td>0.6083</td>\n",
              "      <td>0.7167</td>\n",
              "      <td>0.5733</td>\n",
              "      <td>0.8395</td>\n",
              "      <td>0.9600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>MultiQuery</th>\n",
              "      <td>0.5970</td>\n",
              "      <td>0.8667</td>\n",
              "      <td>0.6783</td>\n",
              "      <td>0.8501</td>\n",
              "      <td>0.9396</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Ensemble</th>\n",
              "      <td>0.5306</td>\n",
              "      <td>0.8667</td>\n",
              "      <td>0.6867</td>\n",
              "      <td>0.8470</td>\n",
              "      <td>0.9531</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                       context_precision  context_recall  \\\n",
              "retriver_name                                              \n",
              "Naive                             0.5649          0.8000   \n",
              "BM25                              0.4583          0.6500   \n",
              "ContextualCompression             0.6833          0.7667   \n",
              "ParentDocument                    0.6083          0.7167   \n",
              "MultiQuery                        0.5970          0.8667   \n",
              "Ensemble                          0.5306          0.8667   \n",
              "\n",
              "                       context_entity_recall  faithfulness  answer_relevancy  \n",
              "retriver_name                                                                 \n",
              "Naive                                 0.7117        0.8182            0.9479  \n",
              "BM25                                  0.5733        0.7171            0.8544  \n",
              "ContextualCompression                 0.6600        0.7595            0.9571  \n",
              "ParentDocument                        0.5733        0.8395            0.9600  \n",
              "MultiQuery                            0.6783        0.8501            0.9396  \n",
              "Ensemble                              0.6867        0.8470            0.9531  "
            ]
          },
          "execution_count": 57,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "results_df = results_df.set_index('retriver_name')\n",
        "results_df"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### LangSmith Evaluation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 58,
      "metadata": {},
      "outputs": [],
      "source": [
        "from langsmith import Client\n",
        "\n",
        "client = Client()\n",
        "\n",
        "dataset_name = \"John Wick Reviews\"\n",
        "\n",
        "langsmith_dataset = client.create_dataset(\n",
        "    dataset_name=dataset_name,\n",
        "    description=\"John Wick Reviews\"\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 59,
      "metadata": {},
      "outputs": [],
      "source": [
        "for data_row in golden_dataset.to_pandas().iterrows():\n",
        "  client.create_example(\n",
        "      inputs={\n",
        "          \"question\": data_row[1][\"user_input\"]\n",
        "      },\n",
        "      outputs={\n",
        "          \"answer\": data_row[1][\"reference\"]\n",
        "      },\n",
        "      metadata={\n",
        "          \"context\": data_row[1][\"reference_contexts\"]\n",
        "      },\n",
        "      dataset_id=langsmith_dataset.id\n",
        "  )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 67,
      "metadata": {},
      "outputs": [],
      "source": [
        "from langsmith.evaluation import LangChainStringEvaluator, evaluate\n",
        "\n",
        "eval_llm = ChatOpenAI(model=\"gpt-4o\")\n",
        "qa_evaluator = LangChainStringEvaluator(\n",
        "    \"qa\", \n",
        "    config={\"llm\" : eval_llm},\n",
        "    prepare_data=lambda run, example: {\n",
        "        \"prediction\": run.outputs[\"response\"],\n",
        "        \"reference\": example.outputs[\"answer\"],\n",
        "        \"input\": example.inputs[\"question\"],\n",
        "    }\n",
        ")\n",
        "\n",
        "def run_langsmith_evaluation(retriever_name, retriever_chain):\n",
        "    evaluate(\n",
        "        retriever_chain.invoke,\n",
        "        data=dataset_name,\n",
        "        evaluators=[qa_evaluator],\n",
        "        metadata={\"revision_id\": retriever_name}\n",
        "    )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 69,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Evaluating Naive\n",
            "View the evaluation results for experiment: 'advanced-reaction-8' at:\n",
            "https://smith.langchain.com/o/df6cd833-569f-46ec-9ae9-90000a6e38c6/datasets/f82d93ec-f21b-4649-8d7e-aa454ad3d78c/compare?selectedSessions=f7e5bf89-6d9b-40b9-b96b-2c948f8d2554\n",
            "\n",
            "\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "1249983183fb4078908f2ce94896de09",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "0it [00:00, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "==================================================\n",
            "\n",
            "Evaluating BM25\n",
            "View the evaluation results for experiment: 'healthy-whistle-63' at:\n",
            "https://smith.langchain.com/o/df6cd833-569f-46ec-9ae9-90000a6e38c6/datasets/f82d93ec-f21b-4649-8d7e-aa454ad3d78c/compare?selectedSessions=48bb66a7-17e1-4853-8894-b370182c293d\n",
            "\n",
            "\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "24f9170b04694a30b4dabe2d00113791",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "0it [00:00, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "==================================================\n",
            "\n",
            "Evaluating ContextualCompression\n",
            "View the evaluation results for experiment: 'monthly-chart-71' at:\n",
            "https://smith.langchain.com/o/df6cd833-569f-46ec-9ae9-90000a6e38c6/datasets/f82d93ec-f21b-4649-8d7e-aa454ad3d78c/compare?selectedSessions=a0108ed6-8acd-4663-b06c-cefc92655abd\n",
            "\n",
            "\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "a2eaa2e5d7fd4082808373f6e699cfc3",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "0it [00:00, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "==================================================\n",
            "\n",
            "Evaluating ParentDocument\n",
            "View the evaluation results for experiment: 'helpful-surprise-55' at:\n",
            "https://smith.langchain.com/o/df6cd833-569f-46ec-9ae9-90000a6e38c6/datasets/f82d93ec-f21b-4649-8d7e-aa454ad3d78c/compare?selectedSessions=6b8f4bbd-f13a-47f6-af8a-ffcd9842a71d\n",
            "\n",
            "\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "e614ef0b241f4e669f3dd382eef7ea61",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "0it [00:00, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "==================================================\n",
            "\n",
            "Evaluating MultiQuery\n",
            "View the evaluation results for experiment: 'pertinent-leather-41' at:\n",
            "https://smith.langchain.com/o/df6cd833-569f-46ec-9ae9-90000a6e38c6/datasets/f82d93ec-f21b-4649-8d7e-aa454ad3d78c/compare?selectedSessions=2b94d175-68d7-4270-a873-dc344bae48d4\n",
            "\n",
            "\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "7056b74bb91f45cb9428ec865cffa229",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "0it [00:00, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "==================================================\n",
            "\n",
            "Evaluating Ensemble\n",
            "View the evaluation results for experiment: 'sparkling-speed-65' at:\n",
            "https://smith.langchain.com/o/df6cd833-569f-46ec-9ae9-90000a6e38c6/datasets/f82d93ec-f21b-4649-8d7e-aa454ad3d78c/compare?selectedSessions=a8d0c069-ca4e-4c62-9a71-3c91452be9c2\n",
            "\n",
            "\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "aa69dfc7d9eb48c19c2e44a9516df396",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "0it [00:00, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "==================================================\n",
            "\n"
          ]
        }
      ],
      "source": [
        "for name, retriever_chain in retriever_chains.items():\n",
        "    print(f\"Evaluating {name}\")\n",
        "    run_langsmith_evaluation(name, retriever_chain)\n",
        "    print(\"\\n\" + \"=\"*50 + \"\\n\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### LangSmith Evaluation Results"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "![LangSmith Evaluation Results](langsmith_experiments.jpeg)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Add Latency and Cost from LangSmith"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 71,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>context_precision</th>\n",
              "      <th>context_recall</th>\n",
              "      <th>context_entity_recall</th>\n",
              "      <th>faithfulness</th>\n",
              "      <th>answer_relevancy</th>\n",
              "      <th>latency</th>\n",
              "      <th>cost</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>retriver_name</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>Naive</th>\n",
              "      <td>0.5649</td>\n",
              "      <td>0.8000</td>\n",
              "      <td>0.7117</td>\n",
              "      <td>0.8182</td>\n",
              "      <td>0.9479</td>\n",
              "      <td>3.98</td>\n",
              "      <td>0.006681</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>BM25</th>\n",
              "      <td>0.4583</td>\n",
              "      <td>0.6500</td>\n",
              "      <td>0.5733</td>\n",
              "      <td>0.7171</td>\n",
              "      <td>0.8544</td>\n",
              "      <td>3.05</td>\n",
              "      <td>0.002804</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>ContextualCompression</th>\n",
              "      <td>0.6833</td>\n",
              "      <td>0.7667</td>\n",
              "      <td>0.6600</td>\n",
              "      <td>0.7595</td>\n",
              "      <td>0.9571</td>\n",
              "      <td>3.51</td>\n",
              "      <td>0.003078</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>ParentDocument</th>\n",
              "      <td>0.6083</td>\n",
              "      <td>0.7167</td>\n",
              "      <td>0.5733</td>\n",
              "      <td>0.8395</td>\n",
              "      <td>0.9600</td>\n",
              "      <td>3.12</td>\n",
              "      <td>0.002037</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>MultiQuery</th>\n",
              "      <td>0.5970</td>\n",
              "      <td>0.8667</td>\n",
              "      <td>0.6783</td>\n",
              "      <td>0.8501</td>\n",
              "      <td>0.9396</td>\n",
              "      <td>7.50</td>\n",
              "      <td>0.009162</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Ensemble</th>\n",
              "      <td>0.5306</td>\n",
              "      <td>0.8667</td>\n",
              "      <td>0.6867</td>\n",
              "      <td>0.8470</td>\n",
              "      <td>0.9531</td>\n",
              "      <td>11.06</td>\n",
              "      <td>0.009952</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                       context_precision  context_recall  \\\n",
              "retriver_name                                              \n",
              "Naive                             0.5649          0.8000   \n",
              "BM25                              0.4583          0.6500   \n",
              "ContextualCompression             0.6833          0.7667   \n",
              "ParentDocument                    0.6083          0.7167   \n",
              "MultiQuery                        0.5970          0.8667   \n",
              "Ensemble                          0.5306          0.8667   \n",
              "\n",
              "                       context_entity_recall  faithfulness  answer_relevancy  \\\n",
              "retriver_name                                                                  \n",
              "Naive                                 0.7117        0.8182            0.9479   \n",
              "BM25                                  0.5733        0.7171            0.8544   \n",
              "ContextualCompression                 0.6600        0.7595            0.9571   \n",
              "ParentDocument                        0.5733        0.8395            0.9600   \n",
              "MultiQuery                            0.6783        0.8501            0.9396   \n",
              "Ensemble                              0.6867        0.8470            0.9531   \n",
              "\n",
              "                       latency      cost  \n",
              "retriver_name                             \n",
              "Naive                     3.98  0.006681  \n",
              "BM25                      3.05  0.002804  \n",
              "ContextualCompression     3.51  0.003078  \n",
              "ParentDocument            3.12  0.002037  \n",
              "MultiQuery                7.50  0.009162  \n",
              "Ensemble                 11.06  0.009952  "
            ]
          },
          "execution_count": 71,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "retriever_stats = {\n",
        "    \"Naive\": {\"latency\": 3.98, \"cost\": 0.00668085},\n",
        "    \"BM25\": {\"latency\": 3.05, \"cost\": 0.0028041},\n",
        "    \"ContextualCompression\": {\"latency\": 3.51, \"cost\": 0.0030783},\n",
        "    \"ParentDocument\": {\"latency\": 3.12, \"cost\": 0.00203745},\n",
        "    \"MultiQuery\": {\"latency\": 7.50, \"cost\": 0.0091617},\n",
        "    \"Ensemble\": {\"latency\": 11.06, \"cost\": 0.00995205}\n",
        "}\n",
        "\n",
        "for name, stats in retriever_stats.items():\n",
        "    results_df.loc[results_df.index == name, 'latency'] = stats['latency']\n",
        "    results_df.loc[results_df.index == name, 'cost'] = stats['cost']\n",
        "\n",
        "results_df"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Best Retriever Analysis\n",
        "Based on the *retriever-specific* evaluation metrics (context precision, context recall, context entity recall) and operational considerations (latency, cost), the optimal retriever choice ***depends on specific use case requirements***. For applications where *precision is paramount*, the **Contextual Compression** retriever stands out with the highest context precision score, while maintaining moderate latency and cost. This makes it ideal for scenarios where accuracy is crucial, but some latency and cost can be tolerated. For use cases that *prioritize recall*, such as comprehensive question answering, the **Multi-Query** retriever excels with the highest context recall, though at higher latency and cost. If *budget constraints* are a primary concern, the **Parent Document** retriever offers the lowest cost and a relatively low latency, making it suitable for cost-sensitive applications, despite its lower recall metrics. The **BM25** retriever provides a balanced approach with moderate precision and recall, low latency and cost, making it a viable option for *general-purpose* use. Lastly, the **Ensemble** retriever, while having the highest operational cost and latency, offers a balanced performance across multiple metrics, making it suitable for *mission-critical* applications where the highest accuracy justifies the expense."
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.1"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
